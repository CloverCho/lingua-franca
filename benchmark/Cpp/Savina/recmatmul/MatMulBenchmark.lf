/**
 * Parallelism benchmark from the Savina benchmark suite.
 * See https://shamsimam.github.io/papers/2014-agere-savina.pdf.
 * 
 * @author Hannes Klein
 */



target Cpp {
    build-type : RelWithDebInfo,
    cmake-include: "MatMul.cmake"
};

import BenchmarkRunner from "../BenchmarkRunner.lf";

reactor Master(numWorkers:int(20), dataLength:int(1024)) {
    
    public preamble {=
        #include "MatMulCommon.hh"
        #include "reactor-cpp/logging.hh"
        #include <bitset>
        #include <list>
    =}
    
    state numWorkersTerminated:int(0);
    state numWorkSent:int(0);
    state numWorkCompleted:int(0);
    state workersWorking:{=std::bitset<20>=};
    state workList:{=std::list<WorkMessage>=};
    state problemSolved:bool(false);
    
    input inStart:void;
    output outFinished:void;
    input inInitializeStart:void;
    output outInitializeFinished:void;
    input inCleanupIterationStart:void;
    output outCleanupIterationFinished:void;
    
    output[20] outWorkersWork:{=WorkMessage=};
    input[20] inWorkersWork:{=std::list<WorkMessage>=};
    output[20] outWorkers:{=Message=};
    input[20] inWorkers:{=Message=};
    
    logical action sendWork:void;
    logical action shutdownWorkers:void;
    
    reaction(inInitializeStart) -> outInitializeFinished {=
        initializeData(dataLength);
        outInitializeFinished.set();
    =}
    
    reaction(inCleanupIterationStart) -> outCleanupIterationFinished {=
        bool isValid = valid(dataLength);
        reactor::log::Info() << std::boolalpha << "Result valid = " << isValid << std::noboolalpha;
        initializeData(dataLength);
        outCleanupIterationFinished.set();
    =}
    
    reaction(inStart) -> sendWork {=
        
        // reset local state
        numWorkersTerminated = 0;
        numWorkSent = 0;
        numWorkCompleted = 0;
        workersWorking.reset();
        workList.clear();
        problemSolved = false;
    
        // start execution
        int numBlocks = dataLength * dataLength;
        workList.emplace_back(0, 0, 0, 0, 0, 0, 0, numBlocks, dataLength);
        sendWork.schedule();
    =}
    
    reaction(sendWork) -> outWorkersWork, shutdownWorkers {=
        
        reactor::log::Debug() << "sending work. I have currently " << workList.size() << " pieces of work and " << workersWorking.count() << " workers are working.";
        if(problemSolved) return;
        if(workList.empty()) {
            // Assuming that no worker is working in parallel.
            // Shutdown because with no work left,
            // there is no shortest path to be found.
            problemSolved = true;
            shutdownWorkers.schedule();
            return;
        }
        
        // The scheduling here has to make sure that no two reactors
        // are accessing the same entries in C at the same time,
        // otherwise we have race conditions and potentially lost updates.
        if(workersWorking.all()) return;
        if(workList.empty()) return;
        auto compare = [](const WorkMessage& w1, const WorkMessage& w2) -> bool {
            return w1.dim > w2.dim;
        };
        workList.sort(compare); // sort for efficiency: generate new pieces of work first
        //int dimToSchedule = begin(workList)->dim;
        std::set<std::pair<int,int>> partsGivenOut;
        int freeWorkerIndex = 0;
        while(workersWorking[freeWorkerIndex]) ++freeWorkerIndex; // out of bounds ruled out
        
        for(auto work = begin(workList); work != end(workList); work++) {
            //if(work->dim != dimToSchedule) break; //only schedule work of the same dim in one run
            bool inserted = partsGivenOut.emplace(std::pair<int,int>(work->srC,work->scC)).second;
            
            if(inserted) {
                outWorkersWork[freeWorkerIndex].set(*work);
                work = workList.erase(work);
                workersWorking[freeWorkerIndex] = true;
                numWorkSent += 1;
                if(workersWorking.all()) break;
                while(workersWorking[freeWorkerIndex]) ++freeWorkerIndex; // out of bounds ruled out
            }
        }
    =}
    
    reaction(shutdownWorkers) -> outWorkers {=
        
        // Assuming that it is safe to shut down the workers
        auto msg = reactor::make_immutable_value<Message>(Message{StopMsg});
        for(int i = 0; i < outWorkers.size(); i++) {
            outWorkers[i].set(msg);
        }
    =}
    
    reaction(inWorkersWork) {=
        
        for(int i = 0; i < inWorkersWork.size(); i++) {
            if(inWorkersWork[i].is_present()) {
                
                workList.insert( end(workList), begin(*(inWorkersWork[i].get())), end(*(inWorkersWork[i].get())) );
            }
        }
        // Do not schedule work here.
        // Trigger work only after confirmation ReceivedMsg.
        // We assume that ReceivedMsg arrives after this reaction is executed.
    =}
    
    reaction(inWorkers) -> outFinished, sendWork {=
        
        for(int i = 0; i < inWorkers.size(); i++) {
            if(inWorkers[i].is_present()) {
                
                if(inWorkers[i].get()->type == DoneMsg) {
                    
                    numWorkCompleted += 1;
                    workersWorking[i] = false;
                    sendWork.schedule();
                    reactor::log::Debug() << "Received DoneMsg from worker " << i;
                    
                } else if(inWorkers[i].get()->type == StopMsg) {
                    
                    // Confirmation that worker shut down.
                    numWorkersTerminated += 1;
                    if(numWorkersTerminated == numWorkers) {
                        outFinished.set();
                    }
                }
            }
        }
    =}
}


reactor Worker(instance:int(0), threshold:int(16384)) {
    
    public preamble {=
        #include "MatMulCommon.hh"
        #include "reactor-cpp/logging.hh"
        #include <list>
    =}
    
    state workQueue:{=std::unique_ptr<std::list<WorkMessage>>=}; // linked list
    
    input inWork:{=WorkMessage=}; // work from the master
    output outWork:{=std::list<WorkMessage>=}; // work back to the master to distribute
    input inMaster:{=Message=}; // control messages from the master
    output outMaster:{=Message=}; // control messages to the master
    
    logical action sendDoneMsg:void;
    logical action returnWorkToMaster:void; // execution threshold exceeded, return new work
    logical action sendStop:void;
    
    reaction(sendStop) -> outMaster {=
        outMaster.set(Message{StopMsg});
    =}
    
    reaction(sendDoneMsg) -> outMaster {=
        outMaster.set(Message{DoneMsg});
    =}
    
    reaction(returnWorkToMaster) -> outWork, outMaster, sendDoneMsg {=
        
        outWork.set(*workQueue);
        outMaster.set(Message{DoneMsg});
    =}
    
    reaction(inWork) -> sendDoneMsg, returnWorkToMaster {=
        
        workQueue = std::make_unique<std::list<WorkMessage>>();
        WorkMessage workMessage = *(inWork.get());
        
        int srA = workMessage.srA;
        int scA = workMessage.scA;
        int srB = workMessage.srB;
        int scB = workMessage.scB;
        int srC = workMessage.srC;
        int scC = workMessage.scC;
        int numBlocks = workMessage.numBlocks;
        int dim = workMessage.dim;
        int newPriority = workMessage.priority + 1;
        
        if (numBlocks > threshold) {
            
            int zerDim = 0;
            int newDim = dim / 2;
            int newNumBlocks = numBlocks / 4;
            
            workQueue->emplace_back(newPriority, srA + zerDim, scA + zerDim, srB + zerDim, scB + zerDim, srC + zerDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + newDim, srB + newDim, scB + zerDim, srC + zerDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + zerDim, srB + zerDim, scB + newDim, srC + zerDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + newDim, srB + newDim, scB + newDim, srC + zerDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + zerDim, srB + zerDim, scB + zerDim, srC + newDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + newDim, srB + newDim, scB + zerDim, srC + newDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + zerDim, srB + zerDim, scB + newDim, srC + newDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + newDim, srB + newDim, scB + newDim, srC + newDim, scC + newDim, newNumBlocks, newDim);
            
            returnWorkToMaster.schedule();
            return;
        }
        
        int endR = srC + dim;
        int endC = scC + dim;
        
        int i = srC;
        while(i < endR) {
            int j = scC;
            while(j < endC) {
                int k = 0;
                while(k < dim) {
                    reactor::log::Debug() << i << " " << j << " " << scA + k << " " << srB + k << " ";
                    C->at(i)[j] += A->at(i)[scA + k] * B->at(srB + k)[j];
                    k += 1;
                }
                j += 1;
            }
            i += 1;
        }
        
        sendDoneMsg.schedule();
    =}
    
    reaction(inMaster) -> sendStop {=
        
        if(inMaster.get()->type == StopMsg) {
            sendStop.schedule();
        }
    =}
}

main reactor DictionaryBenchmark(numIterations:int(12), dataLength:int(1024), blockThreshold:int(16384), priorities:int(10)) {
    
    master = new Master(numWorkers=20, dataLength=dataLength);
    runner = new BenchmarkRunner(numIterations=numIterations, useInit=true, useCleanupIteration=true);
    
    runner.outInitializeStart -> master.inInitializeStart;
    master.outInitializeFinished -> runner.inInitializeFinish;
    
    runner.outCleanupIterationStart -> master.inCleanupIterationStart;
    master.outCleanupIterationFinished -> runner.inCleanupIterationFinish;
    
    runner.outIterationStart -> master.inStart;
    master.outFinished -> runner.inIterationFinish;
    
    reaction(startup) -> runner.inStart {=
        
        printBenchmarkInfo("MatMulBenchmark");
        printArgs("numIterations", numIterations, "dataLength", dataLength, "blockThreshold", blockThreshold, "priorities", priorities, "numWorkers", 20);
        printSystemInfo();
        runner.inStart.set();
    =}
    
    workers = new[20] Worker();
    
    workers.outMaster -> master.inWorkers;
    workers.outWork -> master.inWorkersWork;
    master.outWorkers -> workers.inMaster;
    master.outWorkersWork -> workers.inWork;
}