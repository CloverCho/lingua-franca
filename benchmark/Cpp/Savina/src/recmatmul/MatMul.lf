/**
 * Parallelism benchmark from the Savina benchmark suite.
 * See https://shamsimam.github.io/papers/2014-agere-savina.pdf.
 * 
 * @author Hannes Klein
 */

target Cpp {
    build-type : RelWithDebInfo,
    logging: "info"
};

import BenchmarkRunner from "../BenchmarkRunner.lf";

public preamble {=
    #include <deque>
    #include <cmath>
    
    using Matrix = std::vector<std::vector<double>>;
    
    struct WorkItem {
		size_t srA; // srA = start row in matrix A
		size_t scA; // scA = start column in matrix A
		size_t srB;
		size_t scB;
		size_t srC;
		size_t scC;
		size_t numBlocks; // total number of elements per block in both dimensions
		size_t dim; // number of elements in one dimension in one block
    };
=}

reactor Manager(numWorkers: size_t{20}, dataLength: size_t{1024}) {
    state A: Matrix(dataLength, {=std::vector<double>(dataLength)=});
    state B: Matrix(dataLength, {=std::vector<double>(dataLength)=});
    state C: Matrix;
    
    state workQueue: std::deque<{=reactor::ImmutableValuePtr<WorkItem>=}>;
    
    logical action next;
    logical action done;
    
    input start: void;
    output finished: void;
    
    output data: {=std::tuple<const Matrix*, const Matrix*, Matrix*>=};
    output[numWorkers] doWork: WorkItem;
    input[numWorkers] moreWork: {=std::array<reactor::ImmutableValuePtr<WorkItem>, 8>=};
   
    reaction (startup) {=
        // Fill both input arrays with data
        for (size_t i{0}; i < dataLength; ++i) {
            for (size_t j{0}; j < dataLength; ++j) {
				A[i][j] = i;
        		B[i][j] = j;
			}
        }
    =}
    
    reaction (start) -> data, next {=
        // reset the result matrix C
        C = std::vector<std::vector<double>>(dataLength, std::vector<double>(dataLength));

        // send pointers to all 3 matrixes to the workers
        data.set(std::make_tuple(&A, &B, &C));
        
        // produce the first work item, instructing the worker to multiply the complete matrix
        size_t numBlocks = dataLength * dataLength;
        auto item = reactor::make_immutable_value<WorkItem>(WorkItem{0, 0, 0, 0, 0, 0, numBlocks, dataLength});
        workQueue.emplace_back(std::move(item));
        // and start the first iteration
        next.schedule();
    =}
    
    reaction (next) -> next, done, doWork {=
        if (workQueue.empty()) {
            // we are done if there is no more work
            done.schedule();
        } else {
            // send a work item to each worker (until there is no more work)
            for (size_t i{0}; i < numWorkers && !workQueue.empty(); i++) {
                doWork[i].set(workQueue.front());
                workQueue.pop_front();
            }
            // and schedule the next iteration
            next.schedule();
        }
    =}
    
    reaction (moreWork) {=
        // append all work items received from the workers to the internal work queue
        for (const auto& port : moreWork) {
            if (port.is_present()) {
                const auto& items = *port.get();
                if (!items.empty()) {
                	workQueue.insert(workQueue.end(), items.begin(), items.end());
               	}
            }
        }
    =}
    
    reaction (done) -> finished {=
        bool valid = isValid();
        reactor::log::Info() << std::boolalpha << "Result valid = " << valid << std::noboolalpha;
        finished.set();
    =}
    
    method isValid(): bool {=
        for (size_t i{0}; i < dataLength; i++) {
		    for (size_t j{0}; j < dataLength; j++) {
			    double actual = C[i][j];
			    double expected = 1.0 * dataLength * i * j;
		        if (fabs(actual-expected) > 0.0001) { // allow some rounding errors
			        reactor::log::Info() << "Validation failed for (i,j)=" << i << "," << j << " with (" << actual << "," << expected << ")";
			        return false;    
			    }
			}
		}
		return true;
    =}
}

/*reactor Master(numWorkers:int(20), dataLength:int(1024)) {
    
    public preamble {=
        #include "MatMulCommon.hh"
        #include "reactor-cpp/logging.hh"
        #include <bitset>
        #include <list>
    =}
    
    state numWorkersTerminated:int(0);
    state numWorkSent:int(0);
    state numWorkCompleted:int(0);
    state workersWorking:{=std::bitset<20>=};
    // [[[end]]]
    state workList:{=std::list<WorkMessage>=};
    state problemSolved:bool(false);
    
    input inStart:void;
    output outFinished:void;
    input inInitializeStart:void;
    output outInitializeFinished:void;
    input inCleanupIterationStart:void;
    output outCleanupIterationFinished:void;
    
    output[20] outWorkersWork:{=WorkMessage=};
    input[20] inWorkersWork:{=std::list<WorkMessage>=};
    output[20] outWorkers:{=Message=};
    input[20] inWorkers:{=Message=};
    // [[[end]]]
    
    logical action sendWork:void;
    logical action shutdownWorkers:void;
    
    reaction(inInitializeStart) -> outInitializeFinished {=
        initializeData(dataLength);
        outInitializeFinished.set();
    =}
    
    reaction(inCleanupIterationStart) -> outCleanupIterationFinished {=
        bool isValid = valid(dataLength);
        reactor::log::Info() << std::boolalpha << "Result valid = " << isValid << std::noboolalpha;
        initializeData(dataLength);
        outCleanupIterationFinished.set();
    =}
    
    reaction(inStart) -> sendWork {=
        
        // reset local state
        numWorkersTerminated = 0;
        numWorkSent = 0;
        numWorkCompleted = 0;
        workersWorking.reset();
        workList.clear();
        problemSolved = false;
    
        // start execution
        int numBlocks = dataLength * dataLength;
        workList.emplace_back(0, 0, 0, 0, 0, 0, 0, numBlocks, dataLength);
        sendWork.schedule();
    =}
    
    reaction(sendWork) -> outWorkersWork, shutdownWorkers {=
        
        reactor::log::Debug() << "sending work. I have currently " << workList.size() << " pieces of work and " << workersWorking.count() << " workers are working.";
        if(problemSolved) return;
        if(workList.empty()) {
            // Assuming that no worker is working in parallel.
            // Shutdown because with no work left,
            // there is no shortest path to be found.
            problemSolved = true;
            shutdownWorkers.schedule();
            return;
        }
        
        // The scheduling here has to make sure that no two reactors
        // are accessing the same entries in C at the same time,
        // otherwise we have race conditions and potentially lost updates.
        if(workersWorking.all()) return;
        if(workList.empty()) return;
        auto compare = [](const WorkMessage& w1, const WorkMessage& w2) -> bool {
            return w1.dim > w2.dim;
        };
        workList.sort(compare); // sort for efficiency: generate new pieces of work first
        //int dimToSchedule = begin(workList)->dim;
        std::set<std::pair<int,int>> partsGivenOut;
        int freeWorkerIndex = 0;
        while(workersWorking[freeWorkerIndex]) ++freeWorkerIndex; // out of bounds ruled out
        
        for(auto work = begin(workList); work != end(workList); work++) {
            //if(work->dim != dimToSchedule) break; //only schedule work of the same dim in one run
            bool inserted = partsGivenOut.emplace(std::pair<int,int>(work->srC,work->scC)).second;
            
            if(inserted) {
                outWorkersWork[freeWorkerIndex].set(*work);
                work = workList.erase(work);
                workersWorking[freeWorkerIndex] = true;
                numWorkSent += 1;
                if(workersWorking.all()) break;
                while(workersWorking[freeWorkerIndex]) ++freeWorkerIndex; // out of bounds ruled out
            }
        }
    =}
    
    reaction(shutdownWorkers) -> outWorkers {=
        
        // Assuming that it is safe to shut down the workers
        auto msg = reactor::make_immutable_value<Message>(Message{StopMsg});
        for(int i = 0; i < outWorkers.size(); i++) {
            outWorkers[i].set(msg);
        }
    =}
    
    reaction(inWorkersWork) {=
        
        for(int i = 0; i < inWorkersWork.size(); i++) {
            if(inWorkersWork[i].is_present()) {
                
                workList.insert( end(workList), begin(*(inWorkersWork[i].get())), end(*(inWorkersWork[i].get())) );
            }
        }
        // Do not schedule work here.
        // Trigger work only after confirmation ReceivedMsg.
        // We assume that ReceivedMsg arrives after this reaction is executed.
    =}
    
    reaction(inWorkers) -> outFinished, sendWork {=
        
        for(int i = 0; i < inWorkers.size(); i++) {
            if(inWorkers[i].is_present()) {
                
                if(inWorkers[i].get()->type == DoneMsg) {
                    
                    numWorkCompleted += 1;
                    workersWorking[i] = false;
                    sendWork.schedule();
                    reactor::log::Debug() << "Received DoneMsg from worker " << i;
                    
                } else if(inWorkers[i].get()->type == StopMsg) {
                    
                    // Confirmation that worker shut down.
                    numWorkersTerminated += 1;
                    if(numWorkersTerminated == numWorkers) {
                        outFinished.set();
                    }
                }
            }
        }
    =}
}


reactor Worker(instance:int(0), threshold:int(16384)) {
    
    public preamble {=
        #include "MatMulCommon.hh"
        #include "reactor-cpp/logging.hh"
        #include <list>
    =}
    
    state workQueue:{=std::unique_ptr<std::list<WorkMessage>>=}; // linked list
    
    input inWork:{=WorkMessage=}; // work from the master
    output outWork:{=std::list<WorkMessage>=}; // work back to the master to distribute
    input inMaster:{=Message=}; // control messages from the master
    output outMaster:{=Message=}; // control messages to the master
    
    logical action sendDoneMsg:void;
    logical action returnWorkToMaster:void; // execution threshold exceeded, return new work
    logical action sendStop:void;
    
    reaction(sendStop) -> outMaster {=
        outMaster.set(Message{StopMsg});
    =}
    
    reaction(sendDoneMsg) -> outMaster {=
        outMaster.set(Message{DoneMsg});
    =}
    
    reaction(returnWorkToMaster) -> outWork, outMaster, sendDoneMsg {=
        
        outWork.set(*workQueue);
        outMaster.set(Message{DoneMsg});
    =}
    
    reaction(inWork) -> sendDoneMsg, returnWorkToMaster {=
        
        workQueue = std::make_unique<std::list<WorkMessage>>();
        WorkMessage workMessage = *(inWork.get());
        
        int srA = workMessage.srA;
        int scA = workMessage.scA;
        int srB = workMessage.srB;
        int scB = workMessage.scB;
        int srC = workMessage.srC;
        int scC = workMessage.scC;
        int numBlocks = workMessage.numBlocks;
        int dim = workMessage.dim;
        int newPriority = workMessage.priority + 1;
        
        if (numBlocks > threshold) {
            
            int zerDim = 0;
            int newDim = dim / 2;
            int newNumBlocks = numBlocks / 4;
            
            workQueue->emplace_back(newPriority, srA + zerDim, scA + zerDim, srB + zerDim, scB + zerDim, srC + zerDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + newDim, srB + newDim, scB + zerDim, srC + zerDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + zerDim, srB + zerDim, scB + newDim, srC + zerDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + zerDim, scA + newDim, srB + newDim, scB + newDim, srC + zerDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + zerDim, srB + zerDim, scB + zerDim, srC + newDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + newDim, srB + newDim, scB + zerDim, srC + newDim, scC + zerDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + zerDim, srB + zerDim, scB + newDim, srC + newDim, scC + newDim, newNumBlocks, newDim);
            workQueue->emplace_back(newPriority, srA + newDim, scA + newDim, srB + newDim, scB + newDim, srC + newDim, scC + newDim, newNumBlocks, newDim);
            
            returnWorkToMaster.schedule();
            return;
        }
        
        int endR = srC + dim;
        int endC = scC + dim;
        
        int i = srC;
        while(i < endR) {
            int j = scC;
            while(j < endC) {
                int k = 0;
                while(k < dim) {
                    reactor::log::Debug() << i << " " << j << " " << scA + k << " " << srB + k << " ";
                    C->at(i)[j] += A->at(i)[scA + k] * B->at(srB + k)[j];
                    k += 1;
                }
                j += 1;
            }
            i += 1;
        }
        
        sendDoneMsg.schedule();
    =}
    
    reaction(inMaster) -> sendStop {=
        
        if(inMaster.get()->type == StopMsg) {
            sendStop.schedule();
        }
    =}
}*/

main reactor (numIterations: size_t{12}, dataLength: size_t{1024}, blockThreshold: size_t{16384}, priorities:size_t{10}, numWorkers: size_t{20}) {
    
    runner = new BenchmarkRunner(numIterations=numIterations);
    manager = new Manager(numWorkers=numWorkers, dataLength=dataLength);
    
    reaction(startup) -> runner.inStart {=        
        printBenchmarkInfo("MatMulBenchmark");
        printArgs("numIterations", numIterations, "dataLength", dataLength, "blockThreshold", blockThreshold, "priorities", priorities, "numWorkers", numWorkers);
        printSystemInfo();
        runner.inStart.set();
    =}
}
